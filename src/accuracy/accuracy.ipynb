{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carolmou/linguas-indigenas/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = '../training/checkpoint.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n",
    "model.load_state_dict(torch.load(model_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50265, 768, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/carolmou/.cache/huggingface/datasets/carolmou___parquet/carolmou--random-sentences-b36071ffaba43c26/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "100%|██████████| 2/2 [00:00<00:00, 187.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"carolmou/random-sentences\")[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoCorrectionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self._data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        inputs, target = self._data[idx]\n",
    "        model_inputs = self.tokenizer(inputs, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        labels = self.tokenizer(text_target=target, max_length=self.max_length, padding='max_length', truncation=True, return_tensors='pt')\n",
    "        model_inputs['labels'] = labels['input_ids']\n",
    "\n",
    "        return {type: data[0] for type, data in model_inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_text = data['wrong_text']\n",
    "correct_text = data['correct_text']\n",
    "test_data = list(zip(wrong_text, correct_text))\n",
    "\n",
    "test_dataset = AutoCorrectionDataset(test_data, tokenizer, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dão tivera intenção de dizer isso\n",
      "Não tivera intenção de dizer isso\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "dic = test_dataset[0]\n",
    "input_ids = dic[\"input_ids\"]\n",
    "labels = dic[\"labels\"]\n",
    "\n",
    "print(tokenizer.decode(input_ids, skip_special_tokens=True))\n",
    "print(tokenizer.decode(labels, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary of mistakes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save all the bad words that the spellchecker has to fix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_wrong = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent_wrong, sent_right in test_data:\n",
    "    wrong = sent_wrong.split()\n",
    "    right = sent_right.split()\n",
    "\n",
    "    for w1, w2 in zip(wrong, right):\n",
    "        if w1 != w2:\n",
    "            vocab_wrong[(w1,w2)] = vocab_wrong.get(w1, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_wrong' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vocab_wrong[:\u001b[39m10\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_wrong' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_wrong[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {'wrong': [], 'correction': []}\n",
    "\n",
    "for w1, w2 in vocab_wrong:\n",
    "    df['wrong'].append(w1)\n",
    "    df['correction'].append(w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wrong</th>\n",
       "      <th>correction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>perdoo</td>\n",
       "      <td>Perdão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>perdao</td>\n",
       "      <td>Perdão</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>declamar.</td>\n",
       "      <td>reclamar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reclamam.</td>\n",
       "      <td>reclamar.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Legal,</td>\n",
       "      <td>legal,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451914</th>\n",
       "      <td>t.vo</td>\n",
       "      <td>t.v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451915</th>\n",
       "      <td>Jae-it,</td>\n",
       "      <td>Jae-in,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451916</th>\n",
       "      <td>Jae-is,</td>\n",
       "      <td>Jae-in,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451917</th>\n",
       "      <td>lb:電気</td>\n",
       "      <td>lo:電気</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451918</th>\n",
       "      <td>yo:電気</td>\n",
       "      <td>lo:電気</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>451919 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            wrong correction\n",
       "0          perdoo     Perdão\n",
       "1          perdao     Perdão\n",
       "2       declamar.  reclamar.\n",
       "3       reclamam.  reclamar.\n",
       "4          Legal,     legal,\n",
       "...           ...        ...\n",
       "451914       t.vo        t.v\n",
       "451915    Jae-it,    Jae-in,\n",
       "451916    Jae-is,    Jae-in,\n",
       "451917      lb:電気      lo:電気\n",
       "451918      yo:電気      lo:電気\n",
       "\n",
       "[451919 rows x 2 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/test_wrong_vocabulary.pickle', 'wb') as file:\n",
    "    pickle.dump(df, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1239/1239 [02:26<00:00,  8.47it/s, accuracy=0.311]\n"
     ]
    }
   ],
   "source": [
    "total_samples = 0\n",
    "total_correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loader, leave=True)\n",
    "\n",
    "    for batch in loop:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        predicted_labels = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        # Compare the predicted values with the ground truth labels and count the matches\n",
    "        correct_mask = (predicted_labels == labels)\n",
    "        for ix,sample in enumerate(correct_mask):\n",
    "            if False not in sample:\n",
    "                total_correct += 1\n",
    "\n",
    "        batch_size = batch['input_ids'].shape[0]\n",
    "        total_samples += batch_size \n",
    "\n",
    "        loop.set_postfix({'accuracy': total_correct/total_samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"Ele é engraçada\", max_length=128, padding='max_length', truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = inputs[\"input_ids\"]\n",
    "attention = inputs[\"attention_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = id.to(device)\n",
    "attention = attention.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(input_ids = id, attention_mask = attention)\n",
    "predicted_labels = outputs.logits.argmax(dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0, 28888,  7935, 20407,   763,  3381,  2102,     2,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
       "             1,     1,     1,     1,     1,     1,     1,     1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ele é engraçado'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_labels[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
